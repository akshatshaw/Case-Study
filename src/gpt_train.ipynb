{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatshaw/Case-Study/blob/main/src/gpt_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/akshatshaw/Case-Study"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SonynjPKxkRM",
        "outputId": "e378db22-b277-431e-86ce-2e76fb6f1097"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Case-Study'...\n",
            "remote: Enumerating objects: 37, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 37 (delta 16), reused 26 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (37/37), 1.65 MiB | 13.92 MiB/s, done.\n",
            "Resolving deltas: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Case-Study/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVXZLNqGxxWF",
        "outputId": "6ad87fa6-f423-49e1-d164-bcbd388536b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Case-Study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mnvI-7lbxjZN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "Ofr-ThTWxjZO",
        "outputId": "123e408b-f93b-4375-8e36-36397f03c097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fe    Cr    Ni   Mo    W    N   Nb     C   Si   Mn  ...  \\\n",
              "0  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "1  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "2  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "3  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "4  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "\n",
              "           Test Solution  [Cl-] M   pH  \\\n",
              "0   300 ppm NaCl, pH 7.8   0.0051  7.8   \n",
              "1   500 ppm NaCl, pH 7.8   0.0086  7.8   \n",
              "2  1000 ppm NaCl, pH 7.8   0.0171  7.8   \n",
              "3  5000 ppm NaCl, pH 7.8   0.0856  7.8   \n",
              "4       Seawater Natural   0.5460  8.2   \n",
              "\n",
              "                                         Test Method  Scan Rate mV/s  \\\n",
              "0  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "1  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "2  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "3  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "4  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "\n",
              "   Heat treatment  Microstructures       Comments  Material class  \\\n",
              "0   Not Available    Not Available  S30403 (304L)               1   \n",
              "1   Not Available    Not Available  S30403 (304L)               1   \n",
              "2   Not Available    Not Available  S30403 (304L)               1   \n",
              "3   Not Available    Not Available  S30403 (304L)               1   \n",
              "4   Not Available    Not Available  S30403 (304L)               1   \n",
              "\n",
              "                                        combine_text  \n",
              "0  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "1  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "2  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "3  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "4  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2350ac6-1fe6-4521-9a39-55435522da16\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fe</th>\n",
              "      <th>Cr</th>\n",
              "      <th>Ni</th>\n",
              "      <th>Mo</th>\n",
              "      <th>W</th>\n",
              "      <th>N</th>\n",
              "      <th>Nb</th>\n",
              "      <th>C</th>\n",
              "      <th>Si</th>\n",
              "      <th>Mn</th>\n",
              "      <th>...</th>\n",
              "      <th>Test Solution</th>\n",
              "      <th>[Cl-] M</th>\n",
              "      <th>pH</th>\n",
              "      <th>Test Method</th>\n",
              "      <th>Scan Rate mV/s</th>\n",
              "      <th>Heat treatment</th>\n",
              "      <th>Microstructures</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Material class</th>\n",
              "      <th>combine_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>300 ppm NaCl, pH 7.8</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>7.8</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>500 ppm NaCl, pH 7.8</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>7.8</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1000 ppm NaCl, pH 7.8</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>7.8</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5000 ppm NaCl, pH 7.8</td>\n",
              "      <td>0.0856</td>\n",
              "      <td>7.8</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>Seawater Natural</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>8.2</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2350ac6-1fe6-4521-9a39-55435522da16')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2350ac6-1fe6-4521-9a39-55435522da16 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2350ac6-1fe6-4521-9a39-55435522da16');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b9174064-7c80-43d2-9b7f-caee6235a3e8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b9174064-7c80-43d2-9b7f-caee6235a3e8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b9174064-7c80-43d2-9b7f-caee6235a3e8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data = pd.read_csv(r\"/content/Case-Study/Code/pit_cleaned_final.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXK-X-BfxjZP",
        "outputId": "30a83692-6439-4e85-bd14-0cc65b26fa60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['Fe', 'Cr', 'Ni', 'Mo', 'W', 'N', 'Nb', 'C', 'Si', 'Mn', 'Cu', 'P', 'S',\n",
              "        'Al', 'V', 'Ta', 'Re', 'Ce', 'Ti', 'Co', 'B', 'Mg', 'Y', 'Gd',\n",
              "        'Epit, mV (SCE)', 'Test Temp (C)', '[Cl-] M', 'pH', 'Scan Rate mV/s',\n",
              "        'Material class'],\n",
              "       dtype='object'),\n",
              " Index(['Test Solution', 'Test Method', 'Heat treatment', 'Microstructures',\n",
              "        'Comments', 'combine_text'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "num = data.select_dtypes(include=\"number\").columns\n",
        "cat = data.select_dtypes(exclude=\"number\").columns\n",
        "num, cat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = ['Fe', 'Cr', 'Ni', 'Mo', 'W', 'N', 'Nb', 'C', 'Si', 'Mn', 'Cu', 'P', 'S',\n",
        "        'Al', 'V', 'Ta', 'Re', 'Ce', 'Ti', 'Co', 'B', 'Mg', 'Y', 'Gd',\n",
        "         'Test Temp (C)', '[Cl-] M', 'pH', 'Scan Rate mV/s',\n",
        "        'Material class']\n",
        "num_target = ['Epit, mV (SCE)']"
      ],
      "metadata": {
        "id": "B0-xHAeqyDaJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "57eynBRYxjZP"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data[num] = scaler.fit_transform(data[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic5HTLMdxjZP",
        "outputId": "65f567fb-9139-4c0f-e495-643d2d1dfd1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 640 rows\n",
            "Validation set: 72 rows\n"
          ]
        }
      ],
      "source": [
        "# Creating the data loaders\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(data, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "# Print the sizes\n",
        "print(f\"Train set: {len(train)} rows\")\n",
        "print(f\"Validation set: {len(val)} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF3TJtd8xjZP"
      },
      "source": [
        "### Setting the dataloader for the text data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq_hkzExEHsM",
        "outputId": "6ade0eb3-a8f1-4379-ec6e-1c137651f98a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Case-Study/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eDvOZMTbxjZQ"
      },
      "outputs": [],
      "source": [
        "from gpt import *\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Dataset_txt(Dataset):\n",
        "\n",
        "    def __init__(self, data, tokenizer,txt_col, target = None, max_length=None, pad_token_id=50256):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "        self.txt_col = txt_col\n",
        "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[f\"{txt_col}\"]]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "\n",
        "        self.encoded_texts = [\n",
        "            encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        # label = self.data.iloc[index][f\"{self.target}\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long)\n",
        "            # torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUicbrqZxjZQ",
        "outputId": "eaaffdf9-f5e5-42f0-c540-cd662928d3c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tiktoken\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmppt12KxjZQ",
        "outputId": "810f2c28-6bbe-44d3-c92f-dc28f52f6f9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "640"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_data = Dataset_txt(\n",
        "    data = train,\n",
        "    tokenizer=tokenizer,\n",
        "    txt_col=\"combine_text\",\n",
        "    max_length=512\n",
        ")\n",
        "val_data = Dataset_txt(\n",
        "    data = val,\n",
        "    tokenizer=tokenizer,\n",
        "    txt_col=\"combine_text\",\n",
        "    max_length=512\n",
        ")\n",
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mZfJ9BcrxjZQ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_data,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2rU5DqH1xjZR"
      },
      "outputs": [],
      "source": [
        "class Dataset_Num(Dataset):\n",
        "    def __init__(self, data, numerical_features):\n",
        "        self.data = data\n",
        "        self.numerical_features = numerical_features\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "           torch.tensor(self.data.iloc[index].loc[self.numerical_features], dtype=torch.float),\n",
        "            torch.tensor(self.data.iloc[index].loc[\"Epit, mV (SCE)\"], dtype=torch.float)\n",
        "        )\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GemmPefPxjZR"
      },
      "outputs": [],
      "source": [
        "train_num = Dataset_Num(\n",
        "    data = train,\n",
        "    numerical_features = num\n",
        ")\n",
        "val_num = Dataset_Num(\n",
        "    data = val,\n",
        "    numerical_features = num\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OKwCvB5CxjZR"
      },
      "outputs": [],
      "source": [
        "train_num_loader = DataLoader(\n",
        "    dataset=train_num,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "val_num_loader = DataLoader(\n",
        "    dataset=val_num,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
      ],
      "metadata": {
        "id": "nQyrmAO5EgtJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm38aejzxjZR",
        "outputId": "4a7f1a99-22fb-4288-9a1a-0b3865c2321a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 29]) torch.Size([8])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([8, 29]) torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_num_loader:\n",
        " print(x.shape, y.shape)\n",
        " break\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_num_loader:\n",
        " print(x.shape, y.shape)\n",
        " break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IvuDdg8IxjZR"
      },
      "outputs": [],
      "source": [
        "# loading the orignal model\n",
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "BASE_CONFIG = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 1024,\n",
        " \"drop_rate\": 0.0,\n",
        " \"qkv_bias\": True\n",
        "}\n",
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 256, # We shorten the context length from 1,024 to 256 tokens. Original GPT-2 has a context length of 1,024 tokens.\n",
        " \"emb_dim\": 768,\n",
        " \"n_heads\": 12,\n",
        " \"n_layers\": 12,\n",
        " \"drop_rate\": 0.1,\n",
        " \"qkv_bias\": False\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik2L0wo5xjZR",
        "outputId": "00eaf2bb-07ed-44b2-d87a-b710eb4d1538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 150kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.16MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 202kiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 11.2MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.43MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.39MiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:46<00:00, 10.7MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from gpt_download import download_and_load_gpt2, load_weights_into_gpt\n",
        "from gpt import GPTModel\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "\n",
        "settings, params = download_and_load_gpt2(\n",
        "        model_size=model_size, models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "gpt_model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(gpt_model, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Hr5cRsGDxjZS"
      },
      "outputs": [],
      "source": [
        "gpt_model.eval()\n",
        "for param in gpt_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2iNhyDz3xjZS"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 32 # we take a 32dim output form the gpt model for the representation of text.\n",
        "\n",
        "gpt_model.out_head = torch.nn.Linear(\n",
        " in_features=BASE_CONFIG[\"emb_dim\"],\n",
        " out_features=num_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BLJH59VCxjZS"
      },
      "outputs": [],
      "source": [
        "# For training the final layer norm and last transformer block trainable\n",
        "for param in gpt_model.trf_blocks[-1].parameters():\n",
        " param.requires_grad = True\n",
        "for param in gpt_model.final_norm.parameters():\n",
        " param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RV2boNH7xjZS"
      },
      "outputs": [],
      "source": [
        "class PitModel(torch.nn.Module):\n",
        "    def __init__(self, gpt_model, embedding_dim = num_classes, numerical_features= len(num)):\n",
        "        super().__init__()\n",
        "        self.num_classes = embedding_dim + numerical_features\n",
        "        self.gpt_model = gpt_model\n",
        "        self.linear = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.num_classes, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.3),\n",
        "            torch.nn.Linear(128, 64),\n",
        "            torch.nn.Dropout(0.3),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(64, 32),\n",
        "            torch.nn.Dropout(0.3),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(32, 16),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(16, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_num, x_text):\n",
        "        x = self.gpt_model(x_text)\n",
        "        x = x[:, -1, :]\n",
        "        x = torch.cat((x, x_num), dim=1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "2U1vySYTxjZS"
      },
      "outputs": [],
      "source": [
        "model = PitModel(gpt_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1f-YYLTxjZS",
        "outputId": "f39188dc-35ca-45ff-a56e-cd41d01b6986"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PitModel(\n",
              "  (gpt_model): GPTModel(\n",
              "    (tok_emb): Embedding(50257, 768)\n",
              "    (pos_emb): Embedding(1024, 768)\n",
              "    (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "    (trf_blocks): Sequential(\n",
              "      (0): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (1): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (2): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (3): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (4): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (5): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (6): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (7): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (8): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (9): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (10): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (11): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (final_norm): LayerNorm()\n",
              "    (out_head): Linear(in_features=768, out_features=32, bias=True)\n",
              "  )\n",
              "  (linear): Sequential(\n",
              "    (0): Linear(in_features=61, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.3, inplace=False)\n",
              "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (4): Dropout(p=0.3, inplace=False)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (7): Dropout(p=0.3, inplace=False)\n",
              "    (8): ReLU()\n",
              "    (9): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (10): Dropout(p=0.5, inplace=False)\n",
              "    (11): ReLU()\n",
              "    (12): Linear(in_features=16, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1NzZt3QkxjZS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def calc_loss_batch(num_batch, txt_batch, target_batch, model, device):\n",
        "    num_batch = num_batch.to(device)\n",
        "    txt_batch = txt_batch.to(device)\n",
        "    target_batch = target_batch.float().to(device)\n",
        "\n",
        "    # Forward pass through the model with both numerical and text inputs\n",
        "    predictions = model(num_batch, txt_batch)\n",
        "\n",
        "    # Ensure predictions and targets have the same shape\n",
        "    if predictions.shape != target_batch.shape:\n",
        "        predictions = predictions.squeeze()\n",
        "\n",
        "    # Calculate both MAE and MSE losses\n",
        "    mae_loss = F.l1_loss(predictions, target_batch)\n",
        "    mse_loss = F.mse_loss(predictions, target_batch)\n",
        "\n",
        "    return {'mae': mae_loss, 'mse': mse_loss, 'predictions': predictions, 'targets': target_batch}\n",
        "\n",
        "def calc_loss_loader(data_num_loader, data_txt_loader, model, device, num_batches=None):\n",
        "    total_mae = 0.\n",
        "    total_mse = 0.\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Check if both loaders have data\n",
        "    if len(data_num_loader) == 0 or len(data_txt_loader) == 0:\n",
        "        return {'mae': float(\"nan\"), 'rmse': float(\"nan\"), 'r2': float(\"nan\")}\n",
        "\n",
        "    # Determine number of batches to process\n",
        "    if num_batches is None:\n",
        "        num_batches = min(len(data_num_loader), len(data_txt_loader))\n",
        "    else:\n",
        "        num_batches = min(num_batches, min(len(data_num_loader), len(data_txt_loader)))\n",
        "\n",
        "    # Create iterators for both loaders\n",
        "    num_iterator = iter(data_num_loader)\n",
        "    txt_iterator = iter(data_txt_loader)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        try:\n",
        "            # Get batches from both loaders\n",
        "            num_batch, target_batch = next(num_iterator)\n",
        "            txt_batch = next(txt_iterator)  # Ignore targets from text loader\n",
        "\n",
        "            batch_results = calc_loss_batch(num_batch, txt_batch, target_batch, model, device)\n",
        "\n",
        "            total_mae += batch_results['mae'].item()\n",
        "            total_mse += batch_results['mse'].item()\n",
        "\n",
        "            # Collect predictions and targets for R² calculation\n",
        "            all_predictions.append(batch_results['predictions'].cpu().detach())\n",
        "            all_targets.append(batch_results['targets'].cpu().detach())\n",
        "\n",
        "        except StopIteration:\n",
        "            # Handle case where one loader is exhausted before the other\n",
        "            break\n",
        "\n",
        "    # Calculate final metrics\n",
        "    num_processed_batches = len(all_predictions)\n",
        "    if num_processed_batches == 0:\n",
        "        return {'mae': float(\"nan\"), 'rmse': float(\"nan\"), 'r2': float(\"nan\")}\n",
        "\n",
        "    mae = total_mae / num_processed_batches\n",
        "    rmse = (total_mse / num_processed_batches) ** 0.5\n",
        "\n",
        "    # Calculate R² score\n",
        "    all_predictions = torch.cat(all_predictions).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "    # R² = 1 - (sum of squared residuals / total sum of squares)\n",
        "    ss_res = ((all_targets - all_predictions) ** 2).sum()\n",
        "    ss_tot = ((all_targets - all_targets.mean()) ** 2).sum()\n",
        "\n",
        "    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
        "\n",
        "    return {'mae': mae, 'rmse': rmse, 'r2': r2}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOUoA63BxjZT",
        "outputId": "567bbad7-9443-42c5-aad9-f19f895a8782"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'mae': 387.0145969390869,\n",
              "  'rmse': 475.4997607369929,\n",
              "  'r2': -0.3060274124145508},\n",
              " {'mae': 391.4330325656467,\n",
              "  'rmse': 504.9628471447457,\n",
              "  'r2': -0.5761749744415283})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_num_loader, train_loader, model, device, num_batches=16)\n",
        "    test_loss = calc_loss_loader(train_num_loader, val_loader, model, device, num_batches=16)\n",
        "train_loss, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P7UJchQxjZT",
        "outputId": "5c08b4d3-3222-4239-94d3-785528afb913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makshatshaw47\u001b[0m (\u001b[33makshatshaw47-iit-roorkee\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login(key = \"bced44f91fd31f7b8592ded6013d89cebf7cf375\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "boB9IzsFxjZT"
      },
      "outputs": [],
      "source": [
        "def trainer(\n",
        "    model, train_num_loader, train_txt_loader, val_num_loader, val_txt_loader, optimizer, device,\n",
        "    num_epochs, eval_freq, eval_iter, loss_function=\"mse\",\n",
        "    project_name=None, run_name=None):\n",
        "\n",
        "    # Initialize wandb\n",
        "    wandb.init(project=project_name, name=run_name)\n",
        "\n",
        "    # Log hyperparameters\n",
        "    wandb.config.update({\n",
        "        \"epochs\": num_epochs,\n",
        "        \"eval_frequency\": eval_freq,\n",
        "        \"eval_iterations\": eval_iter,\n",
        "        \"optimizer\": optimizer.__class__.__name__,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"device\": device,\n",
        "        \"model_name\": model.__class__.__name__\n",
        "    })\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_maes, val_maes = [], []\n",
        "    train_rmses, val_rmses = [], []\n",
        "    train_r2s, val_r2s = [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Create iterators for the training loaders\n",
        "    num_train_iter = iter(train_num_loader)\n",
        "    txt_train_iter = iter(train_txt_loader)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_mae_loss = 0\n",
        "        epoch_mse_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        # Reset iterators at the beginning of each epoch\n",
        "        num_train_iter = iter(train_num_loader)\n",
        "        txt_train_iter = iter(train_txt_loader)\n",
        "\n",
        "        # Determine number of batches for this epoch\n",
        "        num_batches = min(len(train_num_loader), len(train_txt_loader))\n",
        "\n",
        "        for _ in range(num_batches):\n",
        "            try:\n",
        "                # Get batches from both loaders\n",
        "                num_batch, target_batch = next(num_train_iter)\n",
        "                txt_batch = next(txt_train_iter)  # Ignore targets from text loader\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss_dict = calc_loss_batch(\n",
        "                    num_batch, txt_batch, target_batch, model, device\n",
        "                )\n",
        "                # For backward pass, you can choose either MAE or MSE or a combination\n",
        "                loss = loss_dict[f'{loss_function}']\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                # Track batch-level metrics\n",
        "                epoch_mae_loss += loss_dict['mae'].item()\n",
        "                epoch_mse_loss += loss_dict['mse'].item()\n",
        "                batch_count += 1\n",
        "                examples_seen += num_batch.shape[0]\n",
        "                global_step += 1\n",
        "\n",
        "                # Log batch metrics\n",
        "                wandb.log({\n",
        "                    \"batch_mae\": loss_dict['mae'].item(),\n",
        "                    \"batch_mse\": loss_dict['mse'].item(),\n",
        "                    \"batch_rmse\": loss_dict['mse'].item() ** 0.5,\n",
        "                    \"examples_seen\": examples_seen,\n",
        "                    \"global_step\": global_step\n",
        "                }, step=global_step)\n",
        "\n",
        "                if global_step % eval_freq == 0:\n",
        "                    # Evaluate model\n",
        "                    train_metrics = calc_loss_loader(train_num_loader, train_txt_loader, model, device, eval_iter)\n",
        "                    val_metrics = calc_loss_loader(val_num_loader, val_txt_loader, model, device, eval_iter)\n",
        "\n",
        "                    # Store metrics\n",
        "                    train_losses.append(train_metrics['mae'])\n",
        "                    val_losses.append(val_metrics['mae'])\n",
        "                    train_maes.append(train_metrics['mae'])\n",
        "                    val_maes.append(val_metrics['mae'])\n",
        "                    train_rmses.append(train_metrics['rmse'])\n",
        "                    val_rmses.append(val_metrics['rmse'])\n",
        "                    train_r2s.append(train_metrics['r2'])\n",
        "                    val_r2s.append(val_metrics['r2'])\n",
        "\n",
        "                    # Log evaluation metrics\n",
        "                    wandb.log({\n",
        "                        \"train_mae\": train_metrics['mae'],\n",
        "                        \"val_mae\": val_metrics['mae'],\n",
        "                        \"train_rmse\": train_metrics['rmse'],\n",
        "                        \"val_rmse\": val_metrics['rmse'],\n",
        "                        \"train_r2\": train_metrics['r2'],\n",
        "                        \"val_r2\": val_metrics['r2'],\n",
        "                        \"epoch\": epoch + 1\n",
        "                    }, step=global_step)\n",
        "\n",
        "                    print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                          f\"Train MAE {train_metrics['mae']:.3f}, \"\n",
        "                          f\"Val MAE {val_metrics['mae']:.3f}, \"\n",
        "                          f\"Train R² {train_metrics['r2']:.3f}, \"\n",
        "                          f\"Val R² {val_metrics['r2']:.3f}\")\n",
        "\n",
        "            except StopIteration:\n",
        "                # Handle case where one loader is exhausted before the other\n",
        "                break\n",
        "\n",
        "        # Calculate and log metrics at epoch end\n",
        "        train_metrics = calc_loss_loader(train_num_loader, train_txt_loader, model, device, eval_iter)\n",
        "        val_metrics = calc_loss_loader(val_num_loader, val_txt_loader, model, device, eval_iter)\n",
        "\n",
        "        # Log epoch-level metrics\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"epoch_avg_mae\": epoch_mae_loss / batch_count if batch_count > 0 else float('nan'),\n",
        "            \"epoch_avg_mse\": epoch_mse_loss / batch_count if batch_count > 0 else float('nan'),\n",
        "            \"epoch_avg_rmse\": (epoch_mse_loss / batch_count) ** 0.5 if batch_count > 0 else float('nan'),\n",
        "            \"train_mae\": train_metrics['mae'],\n",
        "            \"val_mae\": val_metrics['mae'],\n",
        "            \"train_rmse\": train_metrics['rmse'],\n",
        "            \"val_rmse\": val_metrics['rmse'],\n",
        "            \"train_r2\": train_metrics['r2'],\n",
        "            \"val_r2\": val_metrics['r2'],\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "        }, step=global_step)\n",
        "\n",
        "        print(f\"Training MAE: {train_metrics['mae']:.4f} | \", end=\"\")\n",
        "        print(f\"Validation MAE: {val_metrics['mae']:.4f} | \", end=\"\")\n",
        "        print(f\"Training RMSE: {train_metrics['rmse']:.4f} | \", end=\"\")\n",
        "        print(f\"Validation RMSE: {val_metrics['rmse']:.4f} | \", end=\"\")\n",
        "        print(f\"Training R²: {train_metrics['r2']:.4f} | \", end=\"\")\n",
        "        print(f\"Validation R²: {val_metrics['r2']:.4f}\")\n",
        "\n",
        "    # Close wandb run\n",
        "    wandb.finish()\n",
        "\n",
        "    results = {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_maes': train_maes,\n",
        "        'val_maes': val_maes,\n",
        "        'train_rmses': train_rmses,\n",
        "        'val_rmses': val_rmses,\n",
        "        'train_r2s': train_r2s,\n",
        "        'val_r2s': val_r2s,\n",
        "        'examples_seen': examples_seen\n",
        "    }\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qzESnrpTxjZT",
        "outputId": "e84aee3d-663f-4a70-b314-8d1f20f99e87"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/Case-Study/src/wandb/run-20250317_141205-bfxyap4f</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num/runs/bfxyap4f' target=\"_blank\">test-run-6</a></strong> to <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num' target=\"_blank\">https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num/runs/bfxyap4f' target=\"_blank\">https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num/runs/bfxyap4f</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train MAE 434.602, Val MAE 369.670, Train R² -0.261, Val R² -0.559\n",
            "Training MAE: 420.8360 | Validation MAE: 369.2649 | Training RMSE: 511.4428 | Validation RMSE: 464.7861 | Training R²: -0.7844 | Validation R²: -0.5560\n",
            "Ep 2 (Step 000100): Train MAE 367.926, Val MAE 368.824, Train R² -0.307, Val R² -0.552\n",
            "Training MAE: 401.4705 | Validation MAE: 367.7331 | Training RMSE: 517.6976 | Validation RMSE: 463.3831 | Training R²: -0.4966 | Validation R²: -0.5467\n",
            "Ep 3 (Step 000200): Train MAE 451.364, Val MAE 365.485, Train R² -0.331, Val R² -0.533\n",
            "Training MAE: 355.2489 | Validation MAE: 362.4262 | Training RMSE: 433.5404 | Validation RMSE: 457.9524 | Training R²: -0.2513 | Validation R²: -0.5106\n",
            "Ep 4 (Step 000300): Train MAE 376.158, Val MAE 349.865, Train R² -0.216, Val R² -0.437\n",
            "Training MAE: 421.9987 | Validation MAE: 351.5709 | Training RMSE: 529.2869 | Validation RMSE: 446.6167 | Training R²: -0.2300 | Validation R²: -0.4368\n",
            "Training MAE: 322.6015 | Validation MAE: 338.5263 | Training RMSE: 418.4269 | Validation RMSE: 428.6126 | Training R²: -0.2851 | Validation R²: -0.3233\n",
            "Ep 6 (Step 000400): Train MAE 359.245, Val MAE 325.123, Train R² -0.116, Val R² -0.294\n",
            "Training MAE: 369.8471 | Validation MAE: 314.9524 | Training RMSE: 486.9979 | Validation RMSE: 410.3641 | Training R²: -0.1888 | Validation R²: -0.2130\n",
            "Ep 7 (Step 000500): Train MAE 323.926, Val MAE 311.651, Train R² -0.184, Val R² -0.193\n",
            "Training MAE: 382.3993 | Validation MAE: 311.6708 | Training RMSE: 504.5864 | Validation RMSE: 403.9177 | Training R²: -0.0809 | Validation R²: -0.1752\n",
            "Ep 8 (Step 000600): Train MAE 395.248, Val MAE 319.021, Train R² -0.065, Val R² -0.193\n",
            "Training MAE: 336.5819 | Validation MAE: 319.4173 | Training RMSE: 445.8400 | Validation RMSE: 412.1713 | Training R²: -0.0841 | Validation R²: -0.2237\n",
            "Ep 9 (Step 000700): Train MAE 346.292, Val MAE 333.453, Train R² -0.058, Val R² -0.251\n",
            "Training MAE: 373.1712 | Validation MAE: 297.7249 | Training RMSE: 468.2694 | Validation RMSE: 382.2717 | Training R²: -0.0332 | Validation R²: -0.0526\n",
            "Training MAE: 396.1846 | Validation MAE: 317.6638 | Training RMSE: 508.6578 | Validation RMSE: 393.7023 | Training R²: -0.1063 | Validation R²: -0.1165\n",
            "Ep 11 (Step 000800): Train MAE 359.275, Val MAE 304.841, Train R² -0.199, Val R² -0.059\n",
            "Training MAE: 384.5779 | Validation MAE: 320.6204 | Training RMSE: 491.0729 | Validation RMSE: 410.7558 | Training R²: -0.1048 | Validation R²: -0.2153\n",
            "Ep 12 (Step 000900): Train MAE 361.905, Val MAE 304.310, Train R² -0.052, Val R² -0.108\n",
            "Training MAE: 350.2110 | Validation MAE: 317.2617 | Training RMSE: 460.8438 | Validation RMSE: 411.7450 | Training R²: -0.0433 | Validation R²: -0.2212\n",
            "Ep 13 (Step 001000): Train MAE 383.162, Val MAE 298.338, Train R² -0.101, Val R² -0.086\n",
            "Training MAE: 355.1987 | Validation MAE: 311.2638 | Training RMSE: 441.2786 | Validation RMSE: 401.8391 | Training R²: -0.1384 | Validation R²: -0.1631\n",
            "Ep 14 (Step 001100): Train MAE 351.054, Val MAE 307.574, Train R² -0.234, Val R² -0.136\n",
            "Training MAE: 353.9844 | Validation MAE: 310.0746 | Training RMSE: 486.3190 | Validation RMSE: 401.8530 | Training R²: -0.0613 | Validation R²: -0.1632\n",
            "Training MAE: 375.6840 | Validation MAE: 319.7334 | Training RMSE: 486.8697 | Validation RMSE: 409.3400 | Training R²: -0.0390 | Validation R²: -0.2069\n",
            "Ep 16 (Step 001200): Train MAE 284.542, Val MAE 302.358, Train R² -0.027, Val R² -0.113\n",
            "Training MAE: 383.0185 | Validation MAE: 316.2356 | Training RMSE: 503.8484 | Validation RMSE: 398.4555 | Training R²: -0.0412 | Validation R²: -0.1436\n",
            "Ep 17 (Step 001300): Train MAE 290.280, Val MAE 308.424, Train R² -0.056, Val R² -0.144\n",
            "Training MAE: 335.6942 | Validation MAE: 311.0666 | Training RMSE: 442.0261 | Validation RMSE: 393.8211 | Training R²: -0.0820 | Validation R²: -0.1172\n",
            "Ep 18 (Step 001400): Train MAE 353.222, Val MAE 329.307, Train R² -0.077, Val R² -0.277\n",
            "Training MAE: 367.1395 | Validation MAE: 290.7736 | Training RMSE: 478.2715 | Validation RMSE: 373.0478 | Training R²: -0.1463 | Validation R²: -0.0024\n",
            "Ep 19 (Step 001500): Train MAE 329.830, Val MAE 302.523, Train R² -0.171, Val R² -0.078\n",
            "Training MAE: 329.4361 | Validation MAE: 297.2600 | Training RMSE: 432.4443 | Validation RMSE: 383.9059 | Training R²: -0.0711 | Validation R²: -0.0616\n",
            "Training MAE: 390.0813 | Validation MAE: 309.0863 | Training RMSE: 510.4603 | Validation RMSE: 391.2061 | Training R²: -0.1457 | Validation R²: -0.1024\n",
            "Ep 21 (Step 001600): Train MAE 346.066, Val MAE 299.588, Train R² -0.100, Val R² -0.053\n",
            "Training MAE: 399.9481 | Validation MAE: 320.9319 | Training RMSE: 518.0410 | Validation RMSE: 420.9050 | Training R²: -0.1070 | Validation R²: -0.2761\n",
            "Ep 22 (Step 001700): Train MAE 433.285, Val MAE 307.786, Train R² -0.023, Val R² -0.138\n",
            "Training MAE: 305.4873 | Validation MAE: 314.9053 | Training RMSE: 437.2303 | Validation RMSE: 404.2482 | Training R²: -0.1783 | Validation R²: -0.1771\n",
            "Ep 23 (Step 001800): Train MAE 321.685, Val MAE 296.492, Train R² -0.050, Val R² -0.040\n",
            "Training MAE: 414.6709 | Validation MAE: 294.0479 | Training RMSE: 512.2559 | Validation RMSE: 393.6640 | Training R²: -0.0022 | Validation R²: -0.1163\n",
            "Ep 24 (Step 001900): Train MAE 304.560, Val MAE 312.544, Train R² -0.122, Val R² -0.149\n",
            "Training MAE: 350.8622 | Validation MAE: 284.7062 | Training RMSE: 440.8503 | Validation RMSE: 380.5563 | Training R²: -0.1387 | Validation R²: -0.0432\n",
            "Training MAE: 329.7127 | Validation MAE: 315.2006 | Training RMSE: 431.2656 | Validation RMSE: 400.0173 | Training R²: -0.0405 | Validation R²: -0.1526\n",
            "Ep 26 (Step 002000): Train MAE 334.144, Val MAE 326.408, Train R² -0.127, Val R² -0.188\n",
            "Training MAE: 366.3577 | Validation MAE: 304.8181 | Training RMSE: 478.9270 | Validation RMSE: 396.0028 | Training R²: -0.0624 | Validation R²: -0.1296\n",
            "Ep 27 (Step 002100): Train MAE 322.276, Val MAE 294.549, Train R² -0.039, Val R² -0.042\n",
            "Training MAE: 330.8027 | Validation MAE: 312.9474 | Training RMSE: 444.9246 | Validation RMSE: 396.7666 | Training R²: -0.1203 | Validation R²: -0.1339\n",
            "Ep 28 (Step 002200): Train MAE 338.880, Val MAE 313.493, Train R² 0.027, Val R² -0.180\n",
            "Training MAE: 353.8224 | Validation MAE: 290.6609 | Training RMSE: 448.9942 | Validation RMSE: 376.7826 | Training R²: -0.0084 | Validation R²: -0.0226\n",
            "Ep 29 (Step 002300): Train MAE 315.776, Val MAE 304.499, Train R² -0.145, Val R² -0.080\n",
            "Training MAE: 335.1698 | Validation MAE: 302.5172 | Training RMSE: 417.2919 | Validation RMSE: 393.6046 | Training R²: -0.0249 | Validation R²: -0.1159\n",
            "Training MAE: 400.9042 | Validation MAE: 309.5838 | Training RMSE: 503.6611 | Validation RMSE: 406.1143 | Training R²: -0.0669 | Validation R²: -0.1880\n",
            "Ep 31 (Step 002400): Train MAE 338.317, Val MAE 308.055, Train R² -0.010, Val R² -0.151\n",
            "Training MAE: 336.1991 | Validation MAE: 317.7971 | Training RMSE: 444.2129 | Validation RMSE: 386.6181 | Training R²: -0.0718 | Validation R²: -0.0767\n",
            "Ep 32 (Step 002500): Train MAE 372.918, Val MAE 289.936, Train R² -0.098, Val R² -0.003\n",
            "Training MAE: 381.4766 | Validation MAE: 286.8718 | Training RMSE: 475.9825 | Validation RMSE: 386.2949 | Training R²: 0.0153 | Validation R²: -0.0749\n",
            "Ep 33 (Step 002600): Train MAE 334.497, Val MAE 311.018, Train R² -0.142, Val R² -0.146\n",
            "Training MAE: 328.9007 | Validation MAE: 327.8055 | Training RMSE: 456.4208 | Validation RMSE: 419.8201 | Training R²: -0.0392 | Validation R²: -0.2695\n",
            "Ep 34 (Step 002700): Train MAE 322.802, Val MAE 294.627, Train R² -0.050, Val R² -0.031\n",
            "Training MAE: 287.1096 | Validation MAE: 308.6200 | Training RMSE: 378.7406 | Validation RMSE: 400.0400 | Training R²: 0.0073 | Validation R²: -0.1527\n",
            "Training MAE: 358.8361 | Validation MAE: 306.9704 | Training RMSE: 448.7432 | Validation RMSE: 396.0842 | Training R²: -0.0121 | Validation R²: -0.1300\n",
            "Ep 36 (Step 002800): Train MAE 385.919, Val MAE 307.717, Train R² -0.057, Val R² -0.112\n",
            "Training MAE: 351.0677 | Validation MAE: 306.5900 | Training RMSE: 450.6156 | Validation RMSE: 388.5300 | Training R²: -0.0696 | Validation R²: -0.0873\n",
            "Ep 37 (Step 002900): Train MAE 352.114, Val MAE 295.870, Train R² -0.082, Val R² -0.087\n",
            "Training MAE: 345.0452 | Validation MAE: 300.7648 | Training RMSE: 442.1376 | Validation RMSE: 386.0308 | Training R²: -0.0484 | Validation R²: -0.0734\n",
            "Ep 38 (Step 003000): Train MAE 385.678, Val MAE 286.675, Train R² -0.044, Val R² 0.032\n",
            "Training MAE: 386.9888 | Validation MAE: 301.3904 | Training RMSE: 497.7969 | Validation RMSE: 397.4571 | Training R²: -0.0901 | Validation R²: -0.1379\n",
            "Ep 39 (Step 003100): Train MAE 344.866, Val MAE 302.967, Train R² 0.073, Val R² -0.132\n",
            "Training MAE: 304.9800 | Validation MAE: 322.9211 | Training RMSE: 410.3004 | Validation RMSE: 409.0148 | Training R²: -0.0473 | Validation R²: -0.2050\n",
            "Training MAE: 354.7421 | Validation MAE: 307.0888 | Training RMSE: 454.7650 | Validation RMSE: 408.0767 | Training R²: -0.1956 | Validation R²: -0.1995\n",
            "Ep 41 (Step 003200): Train MAE 335.378, Val MAE 302.308, Train R² -0.088, Val R² -0.075\n",
            "Training MAE: 279.9852 | Validation MAE: 302.2393 | Training RMSE: 370.1356 | Validation RMSE: 396.2536 | Training R²: -0.0584 | Validation R²: -0.1310\n",
            "Ep 42 (Step 003300): Train MAE 360.183, Val MAE 295.392, Train R² -0.080, Val R² -0.105\n",
            "Training MAE: 357.6781 | Validation MAE: 320.7273 | Training RMSE: 459.6695 | Validation RMSE: 408.3594 | Training R²: -0.1847 | Validation R²: -0.2012\n",
            "Ep 43 (Step 003400): Train MAE 326.396, Val MAE 310.153, Train R² -0.057, Val R² -0.149\n",
            "Training MAE: 368.9451 | Validation MAE: 298.2006 | Training RMSE: 458.1094 | Validation RMSE: 391.0648 | Training R²: -0.0533 | Validation R²: -0.1016\n",
            "Ep 44 (Step 003500): Train MAE 381.871, Val MAE 308.748, Train R² -0.044, Val R² -0.109\n",
            "Training MAE: 368.7133 | Validation MAE: 299.0841 | Training RMSE: 485.7458 | Validation RMSE: 383.8108 | Training R²: -0.0925 | Validation R²: -0.0611\n",
            "Training MAE: 396.3852 | Validation MAE: 315.8962 | Training RMSE: 518.2762 | Validation RMSE: 387.5034 | Training R²: -0.1331 | Validation R²: -0.0816\n",
            "Ep 46 (Step 003600): Train MAE 339.063, Val MAE 293.346, Train R² -0.035, Val R² -0.015\n",
            "Training MAE: 358.4974 | Validation MAE: 301.1940 | Training RMSE: 466.4194 | Validation RMSE: 377.7377 | Training R²: -0.0649 | Validation R²: -0.0278\n",
            "Ep 47 (Step 003700): Train MAE 365.642, Val MAE 300.519, Train R² -0.010, Val R² 0.007\n",
            "Training MAE: 315.8307 | Validation MAE: 309.7724 | Training RMSE: 437.3502 | Validation RMSE: 391.5473 | Training R²: -0.0636 | Validation R²: -0.1043\n",
            "Ep 48 (Step 003800): Train MAE 342.364, Val MAE 307.225, Train R² -0.050, Val R² -0.128\n",
            "Training MAE: 341.0884 | Validation MAE: 307.8967 | Training RMSE: 446.6480 | Validation RMSE: 398.6320 | Training R²: 0.0418 | Validation R²: -0.1446\n",
            "Ep 49 (Step 003900): Train MAE 371.025, Val MAE 319.530, Train R² -0.000, Val R² -0.168\n",
            "Training MAE: 287.2190 | Validation MAE: 296.2790 | Training RMSE: 374.3920 | Validation RMSE: 379.8415 | Training R²: -0.0079 | Validation R²: -0.0392\n",
            "Training MAE: 358.0559 | Validation MAE: 312.4007 | Training RMSE: 479.1677 | Validation RMSE: 394.3613 | Training R²: 0.0046 | Validation R²: -0.1202\n",
            "Ep 51 (Step 004000): Train MAE 314.584, Val MAE 310.680, Train R² -0.115, Val R² -0.164\n",
            "Training MAE: 397.9252 | Validation MAE: 302.1244 | Training RMSE: 492.4593 | Validation RMSE: 393.3521 | Training R²: -0.1446 | Validation R²: -0.1145\n",
            "Ep 52 (Step 004100): Train MAE 310.259, Val MAE 301.984, Train R² -0.127, Val R² -0.098\n",
            "Training MAE: 337.4877 | Validation MAE: 288.8362 | Training RMSE: 453.0088 | Validation RMSE: 375.5908 | Training R²: -0.1238 | Validation R²: -0.0161\n",
            "Ep 53 (Step 004200): Train MAE 331.954, Val MAE 297.314, Train R² -0.116, Val R² -0.008\n",
            "Training MAE: 352.8865 | Validation MAE: 303.8126 | Training RMSE: 467.2046 | Validation RMSE: 394.3402 | Training R²: -0.0175 | Validation R²: -0.1201\n",
            "Ep 54 (Step 004300): Train MAE 304.623, Val MAE 304.423, Train R² -0.077, Val R² -0.054\n",
            "Training MAE: 361.5885 | Validation MAE: 307.7283 | Training RMSE: 459.1972 | Validation RMSE: 379.0435 | Training R²: -0.0638 | Validation R²: -0.0349\n",
            "Training MAE: 313.4819 | Validation MAE: 290.9354 | Training RMSE: 410.5432 | Validation RMSE: 369.5075 | Training R²: 0.0076 | Validation R²: 0.0165\n",
            "Ep 56 (Step 004400): Train MAE 340.635, Val MAE 288.331, Train R² -0.057, Val R² 0.060\n",
            "Training MAE: 343.0368 | Validation MAE: 308.4425 | Training RMSE: 446.3946 | Validation RMSE: 391.2906 | Training R²: -0.0467 | Validation R²: -0.1028\n",
            "Ep 57 (Step 004500): Train MAE 329.862, Val MAE 298.826, Train R² 0.028, Val R² -0.100\n",
            "Training MAE: 366.3401 | Validation MAE: 305.2501 | Training RMSE: 454.0190 | Validation RMSE: 385.0928 | Training R²: -0.0513 | Validation R²: -0.0682\n",
            "Ep 58 (Step 004600): Train MAE 420.919, Val MAE 294.679, Train R² -0.131, Val R² -0.073\n",
            "Training MAE: 303.8979 | Validation MAE: 311.0006 | Training RMSE: 392.0498 | Validation RMSE: 395.6250 | Training R²: -0.0543 | Validation R²: -0.1274\n",
            "Ep 59 (Step 004700): Train MAE 353.240, Val MAE 302.791, Train R² -0.007, Val R² -0.047\n",
            "Training MAE: 310.5762 | Validation MAE: 312.8410 | Training RMSE: 411.1576 | Validation RMSE: 403.0209 | Training R²: -0.0477 | Validation R²: -0.1700\n",
            "Training MAE: 321.6309 | Validation MAE: 297.1371 | Training RMSE: 427.1938 | Validation RMSE: 382.2010 | Training R²: -0.1664 | Validation R²: -0.0522\n",
            "Ep 61 (Step 004800): Train MAE 393.790, Val MAE 308.519, Train R² -0.313, Val R² -0.128\n",
            "Training MAE: 419.5811 | Validation MAE: 309.8354 | Training RMSE: 519.4443 | Validation RMSE: 385.9172 | Training R²: 0.0041 | Validation R²: -0.0728\n",
            "Ep 62 (Step 004900): Train MAE 354.255, Val MAE 292.663, Train R² -0.088, Val R² -0.071\n",
            "Training MAE: 303.8485 | Validation MAE: 294.2803 | Training RMSE: 391.5969 | Validation RMSE: 385.1795 | Training R²: -0.0683 | Validation R²: -0.0687\n",
            "Ep 63 (Step 005000): Train MAE 357.127, Val MAE 301.281, Train R² 0.021, Val R² -0.084\n",
            "Training MAE: 332.8458 | Validation MAE: 293.0039 | Training RMSE: 429.0733 | Validation RMSE: 376.2621 | Training R²: -0.0065 | Validation R²: -0.0198\n",
            "Ep 64 (Step 005100): Train MAE 386.956, Val MAE 301.377, Train R² -0.042, Val R² -0.091\n",
            "Training MAE: 319.6705 | Validation MAE: 297.1498 | Training RMSE: 411.9519 | Validation RMSE: 392.6797 | Training R²: 0.0269 | Validation R²: -0.1107\n",
            "Training MAE: 355.5907 | Validation MAE: 291.6647 | Training RMSE: 457.5935 | Validation RMSE: 378.8141 | Training R²: -0.0679 | Validation R²: -0.0336\n",
            "Ep 66 (Step 005200): Train MAE 382.238, Val MAE 306.065, Train R² 0.041, Val R² -0.047\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.1)\n",
        "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#     optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
        "# )\n",
        "results = trainer(\n",
        "    model,train_num_loader, train_loader, val_num_loader, val_loader, optimizer, device,\n",
        "    num_epochs=200, eval_freq=100, eval_iter=10,\n",
        "    project_name=\"gpt2-corr-txt-num\", run_name=\"test-run-6\"\n",
        ")\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}