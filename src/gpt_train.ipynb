{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshatshaw/Case-Study/blob/main/src/gpt_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/akshatshaw/Case-Study"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SonynjPKxkRM",
        "outputId": "6caa1d84-391f-47e5-bcec-0427da4b34ea"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Case-Study'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 33 (delta 13), reused 28 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (33/33), 1.63 MiB | 19.47 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Case-Study/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVXZLNqGxxWF",
        "outputId": "4da472ea-214c-4d0d-b567-1b7d8e9da0c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Case-Study\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mnvI-7lbxjZN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "Ofr-ThTWxjZO",
        "outputId": "d2733d9d-df5d-48d8-acda-158e36e489fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fe    Cr    Ni   Mo    W    N   Nb     C   Si   Mn  ...  \\\n",
              "0  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "1  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "2  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "3  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "4  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
              "\n",
              "           Test Solution  [Cl-] M   pH  \\\n",
              "0   300 ppm NaCl, pH 7.8   0.0051  7.8   \n",
              "1   500 ppm NaCl, pH 7.8   0.0086  7.8   \n",
              "2  1000 ppm NaCl, pH 7.8   0.0171  7.8   \n",
              "3  5000 ppm NaCl, pH 7.8   0.0856  7.8   \n",
              "4       Seawater Natural   0.5460  8.2   \n",
              "\n",
              "                                         Test Method  Scan Rate mV/s  \\\n",
              "0  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "1  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "2  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "3  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "4  Potentiodynamic Polarization with exposed area...             0.1   \n",
              "\n",
              "   Heat treatment  Microstructures       Comments  Material class  \\\n",
              "0   Not Available    Not Available  S30403 (304L)               1   \n",
              "1   Not Available    Not Available  S30403 (304L)               1   \n",
              "2   Not Available    Not Available  S30403 (304L)               1   \n",
              "3   Not Available    Not Available  S30403 (304L)               1   \n",
              "4   Not Available    Not Available  S30403 (304L)               1   \n",
              "\n",
              "                                        combine_text  \n",
              "0  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "1  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "2  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "3  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "4  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c1ea460-1366-4e61-ae4d-7b3728cf9f86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fe</th>\n",
              "      <th>Cr</th>\n",
              "      <th>Ni</th>\n",
              "      <th>Mo</th>\n",
              "      <th>W</th>\n",
              "      <th>N</th>\n",
              "      <th>Nb</th>\n",
              "      <th>C</th>\n",
              "      <th>Si</th>\n",
              "      <th>Mn</th>\n",
              "      <th>...</th>\n",
              "      <th>Test Solution</th>\n",
              "      <th>[Cl-] M</th>\n",
              "      <th>pH</th>\n",
              "      <th>Test Method</th>\n",
              "      <th>Scan Rate mV/s</th>\n",
              "      <th>Heat treatment</th>\n",
              "      <th>Microstructures</th>\n",
              "      <th>Comments</th>\n",
              "      <th>Material class</th>\n",
              "      <th>combine_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>300 ppm NaCl, pH 7.8</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>7.8</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>500 ppm NaCl, pH 7.8</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>7.8</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1000 ppm NaCl, pH 7.8</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>7.8</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5000 ppm NaCl, pH 7.8</td>\n",
              "      <td>0.0856</td>\n",
              "      <td>7.8</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69.71</td>\n",
              "      <td>18.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>Seawater Natural</td>\n",
              "      <td>0.5460</td>\n",
              "      <td>8.2</td>\n",
              "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
              "      <td>0.1</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>S30403 (304L)</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c1ea460-1366-4e61-ae4d-7b3728cf9f86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c1ea460-1366-4e61-ae4d-7b3728cf9f86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c1ea460-1366-4e61-ae4d-7b3728cf9f86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2eb81be8-b3b7-421a-bf9b-793c4d9b8242\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2eb81be8-b3b7-421a-bf9b-793c4d9b8242')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2eb81be8-b3b7-421a-bf9b-793c4d9b8242 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data = pd.read_csv(r\"/content/Case-Study/Code/pit_cleaned_final.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXK-X-BfxjZP",
        "outputId": "ca8d9c78-0ca0-4e12-8130-770c76ebed82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['Fe', 'Cr', 'Ni', 'Mo', 'W', 'N', 'Nb', 'C', 'Si', 'Mn', 'Cu', 'P', 'S',\n",
              "        'Al', 'V', 'Ta', 'Re', 'Ce', 'Ti', 'Co', 'B', 'Mg', 'Y', 'Gd',\n",
              "        'Epit, mV (SCE)', 'Test Temp (C)', '[Cl-] M', 'pH', 'Scan Rate mV/s',\n",
              "        'Material class'],\n",
              "       dtype='object'),\n",
              " Index(['Test Solution', 'Test Method', 'Heat treatment', 'Microstructures',\n",
              "        'Comments', 'combine_text'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "num = data.select_dtypes(include=\"number\").columns\n",
        "cat = data.select_dtypes(exclude=\"number\").columns\n",
        "num, cat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = ['Fe', 'Cr', 'Ni', 'Mo', 'W', 'N', 'Nb', 'C', 'Si', 'Mn', 'Cu', 'P', 'S',\n",
        "        'Al', 'V', 'Ta', 'Re', 'Ce', 'Ti', 'Co', 'B', 'Mg', 'Y', 'Gd',\n",
        "         'Test Temp (C)', '[Cl-] M', 'pH', 'Scan Rate mV/s',\n",
        "        'Material class']\n",
        "num_target = ['Epit, mV (SCE)']"
      ],
      "metadata": {
        "id": "B0-xHAeqyDaJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "57eynBRYxjZP"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "data[num] = scaler.fit_transform(data[num])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic5HTLMdxjZP",
        "outputId": "34c2f5eb-1668-4c39-8070-3dff6ed203c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 640 rows\n",
            "Validation set: 72 rows\n"
          ]
        }
      ],
      "source": [
        "# Creating the data loaders\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(data, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "# Print the sizes\n",
        "print(f\"Train set: {len(train)} rows\")\n",
        "print(f\"Validation set: {len(val)} rows\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF3TJtd8xjZP"
      },
      "source": [
        "### Setting the dataloader for the text data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq_hkzExEHsM",
        "outputId": "07aa86d0-9b54-49fa-bcb1-581cc08ff50a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Case-Study/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eDvOZMTbxjZQ"
      },
      "outputs": [],
      "source": [
        "from gpt import *\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Dataset_txt(Dataset):\n",
        "\n",
        "    def __init__(self, data, tokenizer,txt_col, target = None, max_length=None, pad_token_id=50256):\n",
        "        self.data = data\n",
        "        self.target = target\n",
        "        self.txt_col = txt_col\n",
        "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[f\"{txt_col}\"]]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "\n",
        "        self.encoded_texts = [\n",
        "            encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        # label = self.data.iloc[index][f\"{self.target}\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long)\n",
        "            # torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUicbrqZxjZQ",
        "outputId": "6be4b7a2-bd18-4deb-9270-35e281bcd476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q tiktoken\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmppt12KxjZQ",
        "outputId": "1f4b98e9-b636-47a8-cf91-de0522dca8c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "640"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_data = Dataset_txt(\n",
        "    data = train,\n",
        "    tokenizer=tokenizer,\n",
        "    txt_col=\"combine_text\",\n",
        "    max_length=512\n",
        ")\n",
        "val_data = Dataset_txt(\n",
        "    data = val,\n",
        "    tokenizer=tokenizer,\n",
        "    txt_col=\"combine_text\",\n",
        "    max_length=512\n",
        ")\n",
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "mZfJ9BcrxjZQ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_data,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "2rU5DqH1xjZR"
      },
      "outputs": [],
      "source": [
        "class Dataset_Num(Dataset):\n",
        "    def __init__(self, data, numerical_features):\n",
        "        self.data = data\n",
        "        self.numerical_features = numerical_features\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "           torch.tensor(self.data.iloc[index].loc[self.numerical_features], dtype=torch.float),\n",
        "            torch.tensor(self.data.iloc[index].loc[\"Epit, mV (SCE)\"], dtype=torch.float)\n",
        "        )\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "GemmPefPxjZR"
      },
      "outputs": [],
      "source": [
        "train_num = Dataset_Num(\n",
        "    data = train,\n",
        "    numerical_features = num\n",
        ")\n",
        "val_num = Dataset_Num(\n",
        "    data = val,\n",
        "    numerical_features = num\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "OKwCvB5CxjZR"
      },
      "outputs": [],
      "source": [
        "train_num_loader = DataLoader(\n",
        "    dataset=train_num,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "val_num_loader = DataLoader(\n",
        "    dataset=val_num,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
      ],
      "metadata": {
        "id": "nQyrmAO5EgtJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rm38aejzxjZR",
        "outputId": "71189737-d2e3-46e3-8aea-f5d5b20a8cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 29]) torch.Size([8])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([8, 29]) torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_num_loader:\n",
        " print(x.shape, y.shape)\n",
        " break\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_num_loader:\n",
        " print(x.shape, y.shape)\n",
        " break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "IvuDdg8IxjZR"
      },
      "outputs": [],
      "source": [
        "# loading the orignal model\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "BASE_CONFIG = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 1024,\n",
        " \"drop_rate\": 0.0,\n",
        " \"qkv_bias\": True\n",
        "}\n",
        "model_configs = {\n",
        " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 256, # We shorten the context length from 1,024 to 256 tokens. Original GPT-2 has a context length of 1,024 tokens.\n",
        " \"emb_dim\": 768,\n",
        " \"n_heads\": 12,\n",
        " \"n_layers\": 12,\n",
        " \"drop_rate\": 0.1,\n",
        " \"qkv_bias\": False\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik2L0wo5xjZR",
        "outputId": "8e938dfe-fd43-4cfd-a5d2-735559398f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 106kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.77MiB/s]\n",
            "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 144kiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 14.5MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 1.80MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.61MiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [02:03<00:00, 11.5MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from gpt_download import download_and_load_gpt2, load_weights_into_gpt\n",
        "from gpt import GPTModel\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "\n",
        "settings, params = download_and_load_gpt2(\n",
        "        model_size=model_size, models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "gpt_model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(gpt_model, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Hr5cRsGDxjZS"
      },
      "outputs": [],
      "source": [
        "gpt_model.eval()\n",
        "for param in gpt_model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2iNhyDz3xjZS"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 64 # we take a 32dim output form the gpt model for the representation of text.\n",
        "\n",
        "gpt_model.out_head = torch.nn.Linear(\n",
        " in_features=BASE_CONFIG[\"emb_dim\"],\n",
        " out_features=num_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "BLJH59VCxjZS"
      },
      "outputs": [],
      "source": [
        "# For training the final layer norm and last transformer block trainable\n",
        "for param in gpt_model.trf_blocks[-1].parameters():\n",
        " param.requires_grad = True\n",
        "for param in gpt_model.final_norm.parameters():\n",
        " param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "RV2boNH7xjZS"
      },
      "outputs": [],
      "source": [
        "class PitModel(torch.nn.Module):\n",
        "    def __init__(self, gpt_model, embedding_dim = 64, numerical_features= len(num)):\n",
        "        super().__init__()\n",
        "        self.num_classes = embedding_dim + numerical_features\n",
        "        self.gpt_model = gpt_model\n",
        "        self.linear = torch.nn.Sequential(\n",
        "            torch.nn.Linear(self.num_classes, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.Linear(128, 64),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(64, 32),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(32, 16),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(16, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_num, x_text):\n",
        "        x = self.gpt_model(x_text)\n",
        "        x = x[:, -1, :]\n",
        "        x = torch.cat((x, x_num), dim=1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "2U1vySYTxjZS"
      },
      "outputs": [],
      "source": [
        "model = PitModel(gpt_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1f-YYLTxjZS",
        "outputId": "031de996-7c98-4584-e4ec-5875b5e67b3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PitModel(\n",
              "  (gpt_model): GPTModel(\n",
              "    (tok_emb): Embedding(50257, 1024)\n",
              "    (pos_emb): Embedding(1024, 1024)\n",
              "    (drop_emb): Dropout(p=0.0, inplace=False)\n",
              "    (trf_blocks): Sequential(\n",
              "      (0): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (1): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (2): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (3): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (4): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (5): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (6): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (7): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (8): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (9): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (10): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (11): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (12): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (13): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (14): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (15): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (16): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (17): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (18): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (19): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (20): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (21): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (22): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (23): TransformerBlock(\n",
              "        (att): MultiHeadAttention(\n",
              "          (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (layers): Sequential(\n",
              "            (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (1): GELU()\n",
              "            (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm()\n",
              "        (norm2): LayerNorm()\n",
              "        (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (final_norm): LayerNorm()\n",
              "    (out_head): Linear(in_features=1024, out_features=64, bias=True)\n",
              "  )\n",
              "  (linear): Sequential(\n",
              "    (0): Linear(in_features=93, out_features=128, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (4): Dropout(p=0.5, inplace=False)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (7): Dropout(p=0.5, inplace=False)\n",
              "    (8): ReLU()\n",
              "    (9): Linear(in_features=32, out_features=16, bias=True)\n",
              "    (10): Dropout(p=0.5, inplace=False)\n",
              "    (11): ReLU()\n",
              "    (12): Linear(in_features=16, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "1NzZt3QkxjZS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def calc_loss_batch(num_batch, txt_batch, target_batch, model, device):\n",
        "    num_batch = num_batch.to(device)\n",
        "    txt_batch = txt_batch.to(device)\n",
        "    target_batch = target_batch.float().to(device)\n",
        "\n",
        "    # Forward pass through the model with both numerical and text inputs\n",
        "    predictions = model(num_batch, txt_batch)\n",
        "\n",
        "    # Ensure predictions and targets have the same shape\n",
        "    if predictions.shape != target_batch.shape:\n",
        "        predictions = predictions.squeeze()\n",
        "\n",
        "    # Calculate both MAE and MSE losses\n",
        "    mae_loss = F.l1_loss(predictions, target_batch)\n",
        "    mse_loss = F.mse_loss(predictions, target_batch)\n",
        "\n",
        "    return {'mae': mae_loss, 'mse': mse_loss, 'predictions': predictions, 'targets': target_batch}\n",
        "\n",
        "def calc_loss_loader(data_num_loader, data_txt_loader, model, device, num_batches=None):\n",
        "    total_mae = 0.\n",
        "    total_mse = 0.\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    # Check if both loaders have data\n",
        "    if len(data_num_loader) == 0 or len(data_txt_loader) == 0:\n",
        "        return {'mae': float(\"nan\"), 'rmse': float(\"nan\"), 'r2': float(\"nan\")}\n",
        "\n",
        "    # Determine number of batches to process\n",
        "    if num_batches is None:\n",
        "        num_batches = min(len(data_num_loader), len(data_txt_loader))\n",
        "    else:\n",
        "        num_batches = min(num_batches, min(len(data_num_loader), len(data_txt_loader)))\n",
        "\n",
        "    # Create iterators for both loaders\n",
        "    num_iterator = iter(data_num_loader)\n",
        "    txt_iterator = iter(data_txt_loader)\n",
        "\n",
        "    for i in range(num_batches):\n",
        "        try:\n",
        "            # Get batches from both loaders\n",
        "            num_batch, target_batch = next(num_iterator)\n",
        "            txt_batch = next(txt_iterator)  # Ignore targets from text loader\n",
        "\n",
        "            batch_results = calc_loss_batch(num_batch, txt_batch, target_batch, model, device)\n",
        "\n",
        "            total_mae += batch_results['mae'].item()\n",
        "            total_mse += batch_results['mse'].item()\n",
        "\n",
        "            # Collect predictions and targets for R² calculation\n",
        "            all_predictions.append(batch_results['predictions'].cpu().detach())\n",
        "            all_targets.append(batch_results['targets'].cpu().detach())\n",
        "\n",
        "        except StopIteration:\n",
        "            # Handle case where one loader is exhausted before the other\n",
        "            break\n",
        "\n",
        "    # Calculate final metrics\n",
        "    num_processed_batches = len(all_predictions)\n",
        "    if num_processed_batches == 0:\n",
        "        return {'mae': float(\"nan\"), 'rmse': float(\"nan\"), 'r2': float(\"nan\")}\n",
        "\n",
        "    mae = total_mae / num_processed_batches\n",
        "    rmse = (total_mse / num_processed_batches) ** 0.5\n",
        "\n",
        "    # Calculate R² score\n",
        "    all_predictions = torch.cat(all_predictions).numpy()\n",
        "    all_targets = torch.cat(all_targets).numpy()\n",
        "\n",
        "    # R² = 1 - (sum of squared residuals / total sum of squares)\n",
        "    ss_res = ((all_targets - all_predictions) ** 2).sum()\n",
        "    ss_tot = ((all_targets - all_targets.mean()) ** 2).sum()\n",
        "\n",
        "    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
        "\n",
        "    return {'mae': mae, 'rmse': rmse, 'r2': r2}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOUoA63BxjZT",
        "outputId": "67f3656c-ff7b-4bd3-8a3b-216530b8f9e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'mae': 389.65295600891113,\n",
              "  'rmse': 463.9709263604914,\n",
              "  'r2': -0.3588773012161255},\n",
              " {'mae': 389.68980916341144,\n",
              "  'rmse': 484.60459612279095,\n",
              "  'r2': -0.35744261741638184})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_num_loader, train_loader, model, device, num_batches=16)\n",
        "    test_loss = calc_loss_loader(train_num_loader, val_loader, model, device, num_batches=16)\n",
        "train_loss, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "9P7UJchQxjZT",
        "outputId": "b2d36c15-591e-4a83-a753-8d4dd0bbd808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makshatshaw47\u001b[0m (\u001b[33makshatshaw47-iit-roorkee\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login(key = \"bced44f91fd31f7b8592ded6013d89cebf7cf375\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "boB9IzsFxjZT"
      },
      "outputs": [],
      "source": [
        "def trainer(\n",
        "    model, train_num_loader, train_txt_loader, val_num_loader, val_txt_loader, optimizer, device,\n",
        "    num_epochs, eval_freq, eval_iter, loss_function=\"mse\",\n",
        "    project_name=None, run_name=None):\n",
        "\n",
        "    # Initialize wandb\n",
        "    wandb.init(project=project_name, name=run_name)\n",
        "\n",
        "    # Log hyperparameters\n",
        "    wandb.config.update({\n",
        "        \"epochs\": num_epochs,\n",
        "        \"eval_frequency\": eval_freq,\n",
        "        \"eval_iterations\": eval_iter,\n",
        "        \"optimizer\": optimizer.__class__.__name__,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "        \"device\": device,\n",
        "        \"model_name\": model.__class__.__name__\n",
        "    })\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_maes, val_maes = [], []\n",
        "    train_rmses, val_rmses = [], []\n",
        "    train_r2s, val_r2s = [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Create iterators for the training loaders\n",
        "    num_train_iter = iter(train_num_loader)\n",
        "    txt_train_iter = iter(train_txt_loader)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_mae_loss = 0\n",
        "        epoch_mse_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        # Reset iterators at the beginning of each epoch\n",
        "        num_train_iter = iter(train_num_loader)\n",
        "        txt_train_iter = iter(train_txt_loader)\n",
        "\n",
        "        # Determine number of batches for this epoch\n",
        "        num_batches = min(len(train_num_loader), len(train_txt_loader))\n",
        "\n",
        "        for _ in range(num_batches):\n",
        "            try:\n",
        "                # Get batches from both loaders\n",
        "                num_batch, target_batch = next(num_train_iter)\n",
        "                txt_batch = next(txt_train_iter)  # Ignore targets from text loader\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss_dict = calc_loss_batch(\n",
        "                    num_batch, txt_batch, target_batch, model, device\n",
        "                )\n",
        "                # For backward pass, you can choose either MAE or MSE or a combination\n",
        "                loss = loss_dict[f'{loss_function}']\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Track batch-level metrics\n",
        "                epoch_mae_loss += loss_dict['mae'].item()\n",
        "                epoch_mse_loss += loss_dict['mse'].item()\n",
        "                batch_count += 1\n",
        "                examples_seen += num_batch.shape[0]\n",
        "                global_step += 1\n",
        "\n",
        "                # Log batch metrics\n",
        "                wandb.log({\n",
        "                    \"batch_mae\": loss_dict['mae'].item(),\n",
        "                    \"batch_mse\": loss_dict['mse'].item(),\n",
        "                    \"batch_rmse\": loss_dict['mse'].item() ** 0.5,\n",
        "                    \"examples_seen\": examples_seen,\n",
        "                    \"global_step\": global_step\n",
        "                }, step=global_step)\n",
        "\n",
        "                if global_step % eval_freq == 0:\n",
        "                    # Evaluate model\n",
        "                    train_metrics = calc_loss_loader(train_num_loader, train_txt_loader, model, device, eval_iter)\n",
        "                    val_metrics = calc_loss_loader(val_num_loader, val_txt_loader, model, device, eval_iter)\n",
        "\n",
        "                    # Store metrics\n",
        "                    train_losses.append(train_metrics['mae'])\n",
        "                    val_losses.append(val_metrics['mae'])\n",
        "                    train_maes.append(train_metrics['mae'])\n",
        "                    val_maes.append(val_metrics['mae'])\n",
        "                    train_rmses.append(train_metrics['rmse'])\n",
        "                    val_rmses.append(val_metrics['rmse'])\n",
        "                    train_r2s.append(train_metrics['r2'])\n",
        "                    val_r2s.append(val_metrics['r2'])\n",
        "\n",
        "                    # Log evaluation metrics\n",
        "                    wandb.log({\n",
        "                        \"train_mae\": train_metrics['mae'],\n",
        "                        \"val_mae\": val_metrics['mae'],\n",
        "                        \"train_rmse\": train_metrics['rmse'],\n",
        "                        \"val_rmse\": val_metrics['rmse'],\n",
        "                        \"train_r2\": train_metrics['r2'],\n",
        "                        \"val_r2\": val_metrics['r2'],\n",
        "                        \"epoch\": epoch + 1\n",
        "                    }, step=global_step)\n",
        "\n",
        "                    print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                          f\"Train MAE {train_metrics['mae']:.3f}, \"\n",
        "                          f\"Val MAE {val_metrics['mae']:.3f}, \"\n",
        "                          f\"Train R² {train_metrics['r2']:.3f}, \"\n",
        "                          f\"Val R² {val_metrics['r2']:.3f}\")\n",
        "\n",
        "            except StopIteration:\n",
        "                # Handle case where one loader is exhausted before the other\n",
        "                break\n",
        "\n",
        "        # Calculate and log metrics at epoch end\n",
        "        train_metrics = calc_loss_loader(train_num_loader, train_txt_loader, model, device, eval_iter)\n",
        "        val_metrics = calc_loss_loader(val_num_loader, val_txt_loader, model, device, eval_iter)\n",
        "\n",
        "        # Log epoch-level metrics\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"epoch_avg_mae\": epoch_mae_loss / batch_count if batch_count > 0 else float('nan'),\n",
        "            \"epoch_avg_mse\": epoch_mse_loss / batch_count if batch_count > 0 else float('nan'),\n",
        "            \"epoch_avg_rmse\": (epoch_mse_loss / batch_count) ** 0.5 if batch_count > 0 else float('nan'),\n",
        "            \"train_mae\": train_metrics['mae'],\n",
        "            \"val_mae\": val_metrics['mae'],\n",
        "            \"train_rmse\": train_metrics['rmse'],\n",
        "            \"val_rmse\": val_metrics['rmse'],\n",
        "            \"train_r2\": train_metrics['r2'],\n",
        "            \"val_r2\": val_metrics['r2'],\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "        }, step=global_step)\n",
        "\n",
        "        print(f\"Training MAE: {train_metrics['mae']:.4f} | \", end=\"\")\n",
        "        print(f\"Validation MAE: {val_metrics['mae']:.4f} | \", end=\"\")\n",
        "        print(f\"Training RMSE: {train_metrics['rmse']:.4f} | \", end=\"\")\n",
        "        print(f\"Validation RMSE: {val_metrics['rmse']:.4f} | \", end=\"\")\n",
        "        print(f\"Training R²: {train_metrics['r2']:.4f} | \", end=\"\")\n",
        "        print(f\"Validation R²: {val_metrics['r2']:.4f}\")\n",
        "\n",
        "    # Close wandb run\n",
        "    wandb.finish()\n",
        "\n",
        "    results = {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_maes': train_maes,\n",
        "        'val_maes': val_maes,\n",
        "        'train_rmses': train_rmses,\n",
        "        'val_rmses': val_rmses,\n",
        "        'train_r2s': train_r2s,\n",
        "        'val_r2s': val_r2s,\n",
        "        'examples_seen': examples_seen\n",
        "    }\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "qzESnrpTxjZT",
        "outputId": "f7af164b-f080-462b-8317-e332957ff281"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/Case-Study/src/wandb/run-20250317_124131-7jc65i2d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num/runs/7jc65i2d' target=\"_blank\">test-run-4</a></strong> to <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num' target=\"_blank\">https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num/runs/7jc65i2d' target=\"_blank\">https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-num/runs/7jc65i2d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train MAE 434.503, Val MAE 369.519, Train R² -0.260, Val R² -0.557\n",
            "Training MAE: 421.1606 | Validation MAE: 369.4147 | Training RMSE: 511.6732 | Validation RMSE: 464.9050 | Training R²: -0.7860 | Validation R²: -0.5568\n",
            "Ep 2 (Step 000100): Train MAE 368.348, Val MAE 369.375, Train R² -0.310, Val R² -0.557\n",
            "Training MAE: 403.3615 | Validation MAE: 369.4218 | Training RMSE: 519.5691 | Validation RMSE: 464.9038 | Training R²: -0.5075 | Validation R²: -0.5568\n",
            "Ep 3 (Step 000200): Train MAE 454.955, Val MAE 369.361, Train R² -0.348, Val R² -0.557\n",
            "Training MAE: 360.7417 | Validation MAE: 369.2195 | Training RMSE: 437.7740 | Validation RMSE: 464.7341 | Training R²: -0.2758 | Validation R²: -0.5557\n",
            "Ep 4 (Step 000300): Train MAE 388.790, Val MAE 369.291, Train R² -0.282, Val R² -0.556\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.1)\n",
        "\n",
        "results = trainer(\n",
        "    model,train_num_loader, train_loader, val_num_loader, val_loader, optimizer, device,\n",
        "    num_epochs=200, eval_freq=100, eval_iter=10,\n",
        "    project_name=\"gpt2-corr-txt-num\", run_name=\"test-run-4\"\n",
        ")\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9SDUCw6xjZU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}