{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AKSHAT SHAW\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"..\\Code\\pit_cleaned_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fe</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Mo</th>\n",
       "      <th>W</th>\n",
       "      <th>N</th>\n",
       "      <th>Nb</th>\n",
       "      <th>C</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mn</th>\n",
       "      <th>...</th>\n",
       "      <th>Test Solution</th>\n",
       "      <th>[Cl-] M</th>\n",
       "      <th>pH</th>\n",
       "      <th>Test Method</th>\n",
       "      <th>Scan Rate mV/s</th>\n",
       "      <th>Heat treatment</th>\n",
       "      <th>Microstructures</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Material class</th>\n",
       "      <th>combine_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.71</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>300 ppm NaCl, pH 7.8</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>S30403 (304L)</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.71</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>500 ppm NaCl, pH 7.8</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>S30403 (304L)</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.71</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000 ppm NaCl, pH 7.8</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>S30403 (304L)</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.71</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5000 ppm NaCl, pH 7.8</td>\n",
       "      <td>0.0856</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>S30403 (304L)</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69.71</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Seawater Natural</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Potentiodynamic Polarization with exposed area...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>S30403 (304L)</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;S&gt; Test Solution: 0       300 ppm NaCl, pH 7....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fe    Cr    Ni   Mo    W    N   Nb     C   Si   Mn  ...  \\\n",
       "0  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
       "1  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
       "2  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
       "3  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
       "4  69.71  18.0  10.0  0.0  0.0  0.0  0.0  0.03  1.0  1.0  ...   \n",
       "\n",
       "           Test Solution  [Cl-] M   pH  \\\n",
       "0   300 ppm NaCl, pH 7.8   0.0051  7.8   \n",
       "1   500 ppm NaCl, pH 7.8   0.0086  7.8   \n",
       "2  1000 ppm NaCl, pH 7.8   0.0171  7.8   \n",
       "3  5000 ppm NaCl, pH 7.8   0.0856  7.8   \n",
       "4       Seawater Natural   0.5460  8.2   \n",
       "\n",
       "                                         Test Method  Scan Rate mV/s  \\\n",
       "0  Potentiodynamic Polarization with exposed area...             0.1   \n",
       "1  Potentiodynamic Polarization with exposed area...             0.1   \n",
       "2  Potentiodynamic Polarization with exposed area...             0.1   \n",
       "3  Potentiodynamic Polarization with exposed area...             0.1   \n",
       "4  Potentiodynamic Polarization with exposed area...             0.1   \n",
       "\n",
       "   Heat treatment  Microstructures       Comments  Material class  \\\n",
       "0   Not Available    Not Available  S30403 (304L)               1   \n",
       "1   Not Available    Not Available  S30403 (304L)               1   \n",
       "2   Not Available    Not Available  S30403 (304L)               1   \n",
       "3   Not Available    Not Available  S30403 (304L)               1   \n",
       "4   Not Available    Not Available  S30403 (304L)               1   \n",
       "\n",
       "                                        combine_text  \n",
       "0  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
       "1  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
       "2  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
       "3  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
       "4  <S> Test Solution: 0       300 ppm NaCl, pH 7....  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = data.select_dtypes(include=\"number\").columns\n",
    "cat = data.select_dtypes(exclude=\"number\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Fe', 'Cr', 'Ni', 'Mo', 'W', 'N', 'Nb', 'C', 'Si', 'Mn', 'Cu', 'P', 'S',\n",
       "        'Al', 'V', 'Ta', 'Re', 'Ce', 'Ti', 'Co', 'B', 'Mg', 'Y', 'Gd',\n",
       "        'Epit, mV (SCE)', 'Test Temp (C)', '[Cl-] M', 'pH', 'Scan Rate mV/s',\n",
       "        'Material class'],\n",
       "       dtype='object'),\n",
       " Index(['Test Solution', 'Test Method', 'Heat treatment', 'Microstructures',\n",
       "        'Comments', 'combine_text'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num, cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 569 rows (70%)\n",
      "Validation set: 71 rows (15%)\n",
      "Test set: 72 rows (15%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, temp = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: separate val and test from temp\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Print the sizes\n",
    "print(f\"Train set: {len(train)} rows (70%)\")\n",
    "print(f\"Validation set: {len(val)} rows (15%)\")\n",
    "print(f\"Test set: {len(test)} rows (15%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MatDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer,txt_col,target, max_length=None, pad_token_id=50256):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.txt_col = txt_col\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[f\"{txt_col}\"]]\n",
    "        \n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "        \n",
    "        self.encoded_texts = [\n",
    "            encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "        \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][f\"{self.target}\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MatDataset(\n",
    "    data = train,\n",
    "    tokenizer=tokenizer,\n",
    "    txt_col=\"combine_text\",\n",
    "    target = \"Epit, mV (SCE)\",\n",
    "    max_length=512\n",
    ")\n",
    "val_data = MatDataset(\n",
    "    data = val,\n",
    "    tokenizer=tokenizer,\n",
    "    txt_col=\"combine_text\",\n",
    "    target = \"Epit, mV (SCE)\",\n",
    "    max_length=512\n",
    ")\n",
    "\n",
    "test_data = MatDataset(\n",
    "    data = test,\n",
    "    tokenizer=tokenizer,\n",
    "    txt_col=\"combine_text\",\n",
    "    target = \"Epit, mV (SCE)\",\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0 \n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 512]) torch.Size([8])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([8, 512]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    " print(x.shape, y.shape)\n",
    " break\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in test_loader:\n",
    " print(x.shape, y.shape)\n",
    " break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the orignal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    " \"vocab_size\": 50257, \n",
    " \"context_length\": 1024, \n",
    " \"drop_rate\": 0.0, \n",
    " \"qkv_bias\": True \n",
    "}\n",
    "model_configs = {\n",
    " \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    " \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    " \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    " \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    " \"vocab_size\": 50257,\n",
    " \"context_length\": 256, # We shorten the context length from 1,024 to 256 tokens. Original GPT-2 has a context length of 1,024 tokens.\n",
    " \"emb_dim\": 768,\n",
    " \"n_heads\": 12,\n",
    " \"n_layers\": 12, \n",
    " \"drop_rate\": 0.1, \n",
    " \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2, load_weights_into_gpt\n",
    "from gpt import GPTModel\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "settings, params = download_and_load_gpt2(                \n",
    "        model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 1\n",
    "model.out_head = torch.nn.Linear(\n",
    " in_features=BASE_CONFIG[\"emb_dim\"], \n",
    " out_features=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the final layer norm and last transformer block trainable\n",
    "\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    " param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    " param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing random words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.6194],\n",
      "         [-3.7575],\n",
      "         [-2.3000],\n",
      "         [-3.6323]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    " outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E(pit) mV: tensor([[-3.6323]])\n"
     ]
    }
   ],
   "source": [
    "probas = outputs[:, -1, :]\n",
    "print(\"E(pit) mV:\", probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_regression_metrics(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    total_mae, total_mse, num_examples = 0, 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                predictions = model(input_batch)[:, -1, :]  # predictions for the last token\n",
    "                if predictions.shape != target_batch.shape:\n",
    "                    predictions = predictions.squeeze()              \n",
    "                # Calculate absolute errors and squared errors\n",
    "                absolute_errors = torch.abs(predictions - target_batch)\n",
    "                squared_errors = (predictions - target_batch) ** 2\n",
    "                # Sum up errors\n",
    "                total_mae += absolute_errors.sum().item()\n",
    "                total_mse += squared_errors.sum().item()\n",
    "                num_examples += target_batch.shape[0]\n",
    "        else:\n",
    "            break\n",
    "    # Calculate final metrics\n",
    "    mae = total_mae / num_examples\n",
    "    rmse = (total_mse / num_examples) ** 0.5\n",
    "    return {'mae': mae, 'rmse': rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_regression_metrics(\n",
    " train_loader, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "test_accuracy = calc_regression_metrics(\n",
    " test_loader, model, device, num_batches=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mae': 460.75789031982424, 'rmse': 547.8676847560914},\n",
       " {'mae': 411.06050957573785, 'rmse': 525.5380989069944})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.float().to(device)\n",
    "    \n",
    "    predictions = model(input_batch)[:, -1, :]\n",
    "    \n",
    "    # Ensure predictions and targets have the same shape\n",
    "    if predictions.shape != target_batch.shape:\n",
    "        predictions = predictions.squeeze()\n",
    "    \n",
    "    # Calculate both MAE and MSE losses\n",
    "    mae_loss = F.l1_loss(predictions, target_batch)\n",
    "    mse_loss = F.mse_loss(predictions, target_batch)\n",
    "    \n",
    "    return {'mae': mae_loss, 'mse': mse_loss, 'predictions': predictions, 'targets': target_batch}\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_mae = 0.\n",
    "    total_mse = 0.\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    if len(data_loader) == 0:\n",
    "        return {'mae': float(\"nan\"), 'rmse': float(\"nan\"), 'r2': float(\"nan\")}\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else: \n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "        \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            batch_results = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            \n",
    "            total_mae += batch_results['mae'].item()\n",
    "            total_mse += batch_results['mse'].item()\n",
    "            \n",
    "            # Collect predictions and targets for R² calculation\n",
    "            all_predictions.append(batch_results['predictions'].cpu().detach())\n",
    "            all_targets.append(batch_results['targets'].cpu().detach())\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    mae = total_mae / num_batches\n",
    "    rmse = (total_mse / num_batches) ** 0.5\n",
    "    \n",
    "    # Calculate R² score\n",
    "    all_predictions = torch.cat(all_predictions).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    \n",
    "    # R² = 1 - (sum of squared residuals / total sum of squares)\n",
    "    ss_res = ((all_targets - all_predictions) ** 2).sum()\n",
    "    ss_tot = ((all_targets - all_targets.mean()) ** 2).sum()\n",
    "    \n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "    \n",
    "    return {'mae': mae, 'rmse': rmse, 'r2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mae': 416.62835083007815,\n",
       "  'rmse': 505.8158477894895,\n",
       "  'r2': -0.3561640977859497},\n",
       " {'mae': 436.3544616699219,\n",
       "  'rmse': 523.4857716547796,\n",
       "  'r2': -0.4374806880950928})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad(): \n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makshatshaw47\u001b[0m (\u001b[33makshatshaw47-iit-roorkee\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regressor_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq, eval_iter, loss_function=\"mse\",\n",
    "    project_name=\"gpt2-corr-txt-only\", run_name=None):\n",
    "    \n",
    "    # Initialize wandb\n",
    "    wandb.init(project=project_name, name=run_name)\n",
    "    \n",
    "    # Log hyperparameters\n",
    "    wandb.config.update({\n",
    "        \"epochs\": num_epochs,\n",
    "        \"eval_frequency\": eval_freq,\n",
    "        \"eval_iterations\": eval_iter,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "        \"device\": device,\n",
    "        \"model_name\": model.__class__.__name__\n",
    "    })\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    train_maes, val_maes = [], []\n",
    "    train_rmses, val_rmses = [], []\n",
    "    train_r2s, val_r2s = [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_mae_loss = 0\n",
    "        epoch_mse_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss_dict = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            # For backward pass, you can choose either MAE or MSE or a combination\n",
    "            loss = loss_dict[f'{loss_function}']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Track batch-level metrics\n",
    "            epoch_mae_loss += loss_dict['mae'].item()\n",
    "            epoch_mse_loss += loss_dict['mse'].item()\n",
    "            batch_count += 1\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "            \n",
    "            # Log batch metrics\n",
    "            wandb.log({\n",
    "                \"batch_mae\": loss_dict['mae'].item(),\n",
    "                \"batch_mse\": loss_dict['mse'].item(),\n",
    "                \"batch_rmse\": loss_dict['mse'].item() ** 0.5,\n",
    "                \"examples_seen\": examples_seen,\n",
    "                \"global_step\": global_step\n",
    "            }, step=global_step)\n",
    "            \n",
    "            if global_step % eval_freq == 0:\n",
    "                # Evaluate model\n",
    "                train_metrics = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "                val_metrics = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "                \n",
    "                # Store metrics\n",
    "                train_losses.append(train_metrics['mae'])  # Using MAE as primary loss to track\n",
    "                val_losses.append(val_metrics['mae'])\n",
    "                train_maes.append(train_metrics['mae'])\n",
    "                val_maes.append(val_metrics['mae'])\n",
    "                train_rmses.append(train_metrics['rmse'])\n",
    "                val_rmses.append(val_metrics['rmse'])\n",
    "                train_r2s.append(train_metrics['r2'])\n",
    "                val_r2s.append(val_metrics['r2'])\n",
    "                \n",
    "                # Log evaluation metrics\n",
    "                wandb.log({\n",
    "                    \"train_mae\": train_metrics['mae'],\n",
    "                    \"val_mae\": val_metrics['mae'],\n",
    "                    \"train_rmse\": train_metrics['rmse'],\n",
    "                    \"val_rmse\": val_metrics['rmse'],\n",
    "                    \"train_r2\": train_metrics['r2'],\n",
    "                    \"val_r2\": val_metrics['r2'],\n",
    "                    \"epoch\": epoch + 1\n",
    "                }, step=global_step)\n",
    "                \n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train MAE {train_metrics['mae']:.3f}, \"\n",
    "                      f\"Val MAE {val_metrics['mae']:.3f}, \"\n",
    "                      f\"Train R² {train_metrics['r2']:.3f}, \"\n",
    "                      f\"Val R² {val_metrics['r2']:.3f}\")\n",
    "        \n",
    "        # Calculate and log metrics at epoch end\n",
    "        train_metrics = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "        val_metrics = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "        \n",
    "        # Log epoch-level metrics\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"epoch_avg_mae\": epoch_mae_loss / batch_count,\n",
    "            \"epoch_avg_mse\": epoch_mse_loss / batch_count,\n",
    "            \"epoch_avg_rmse\": (epoch_mse_loss / batch_count) ** 0.5,\n",
    "            \"train_mae\": train_metrics['mae'],\n",
    "            \"val_mae\": val_metrics['mae'],\n",
    "            \"train_rmse\": train_metrics['rmse'],\n",
    "            \"val_rmse\": val_metrics['rmse'],\n",
    "            \"train_r2\": train_metrics['r2'],\n",
    "            \"val_r2\": val_metrics['r2'],\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        }, step=global_step)\n",
    "        \n",
    "        print(f\"Training MAE: {train_metrics['mae']:.4f} | \", end=\"\")\n",
    "        print(f\"Validation MAE: {val_metrics['mae']:.4f} | \", end=\"\")\n",
    "        print(f\"Training RMSE: {train_metrics['rmse']:.4f} | \", end=\"\")\n",
    "        print(f\"Validation RMSE: {val_metrics['rmse']:.4f} | \", end=\"\")\n",
    "        print(f\"Training R²: {train_metrics['r2']:.4f} | \", end=\"\")\n",
    "        print(f\"Validation R²: {val_metrics['r2']:.4f}\")\n",
    "    \n",
    "    # Close wandb run\n",
    "    wandb.finish()\n",
    "    \n",
    "    results = {\n",
    "        'train_losses': train_losses, \n",
    "        'val_losses': val_losses,\n",
    "        'train_maes': train_maes,\n",
    "        'val_maes': val_maes,\n",
    "        'train_rmses': train_rmses,\n",
    "        'val_rmses': val_rmses,\n",
    "        'train_r2s': train_r2s,\n",
    "        'val_r2s': val_r2s,\n",
    "        'examples_seen': examples_seen\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\AKSHAT SHAW\\OneDrive - iitr.ac.in\\Desktop\\SEM 6\\case-study\\src\\wandb\\run-20250316_230033-ejtm0bh8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only/runs/ejtm0bh8' target=\"_blank\">test-run-2</a></strong> to <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only' target=\"_blank\">https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only/runs/ejtm0bh8' target=\"_blank\">https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only/runs/ejtm0bh8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train MAE 376.506, Val MAE 346.269, Train R² -0.336, Val R² -0.272\n",
      "Training MAE: 375.7124 | Validation MAE: 334.7465 | Training RMSE: 483.9524 | Validation RMSE: 431.8390 | Training R²: -0.2044 | Validation R²: -0.2154\n",
      "Ep 2 (Step 000100): Train MAE 455.789, Val MAE 330.624, Train R² -0.321, Val R² -0.197\n",
      "Training MAE: 340.5808 | Validation MAE: 327.3845 | Training RMSE: 427.0497 | Validation RMSE: 425.9723 | Training R²: -0.1574 | Validation R²: -0.1823\n",
      "Ep 3 (Step 000200): Train MAE 348.789, Val MAE 325.153, Train R² -0.154, Val R² -0.172\n",
      "Training MAE: 404.0240 | Validation MAE: 324.7207 | Training RMSE: 498.1107 | Validation RMSE: 423.8669 | Training R²: -0.3235 | Validation R²: -0.1705\n",
      "Training MAE: 384.5845 | Validation MAE: 322.4172 | Training RMSE: 469.8958 | Validation RMSE: 422.0947 | Training R²: -0.2480 | Validation R²: -0.1607\n",
      "Ep 5 (Step 000300): Train MAE 396.622, Val MAE 321.852, Train R² -0.142, Val R² -0.158\n",
      "Training MAE: 394.2064 | Validation MAE: 320.3392 | Training RMSE: 490.6088 | Validation RMSE: 420.4665 | Training R²: -0.2282 | Validation R²: -0.1516\n",
      "Ep 6 (Step 000400): Train MAE 388.398, Val MAE 319.034, Train R² -0.405, Val R² -0.146\n",
      "Training MAE: 382.4104 | Validation MAE: 318.3087 | Training RMSE: 470.2982 | Validation RMSE: 418.8917 | Training R²: -0.1161 | Validation R²: -0.1429\n",
      "Training MAE: 381.2513 | Validation MAE: 316.4057 | Training RMSE: 470.1635 | Validation RMSE: 417.3673 | Training R²: -0.0471 | Validation R²: -0.1346\n",
      "Ep 8 (Step 000500): Train MAE 366.868, Val MAE 316.301, Train R² -0.317, Val R² -0.134\n",
      "Training MAE: 392.4875 | Validation MAE: 314.6760 | Training RMSE: 506.6852 | Validation RMSE: 415.9566 | Training R²: -0.1578 | Validation R²: -0.1268\n",
      "Ep 9 (Step 000600): Train MAE 442.795, Val MAE 313.874, Train R² -0.242, Val R² -0.123\n",
      "Training MAE: 403.3906 | Validation MAE: 313.0156 | Training RMSE: 507.3520 | Validation RMSE: 414.5048 | Training R²: -0.2544 | Validation R²: -0.1189\n",
      "Ep 10 (Step 000700): Train MAE 329.475, Val MAE 311.678, Train R² -0.129, Val R² -0.113\n",
      "Training MAE: 361.5276 | Validation MAE: 311.4454 | Training RMSE: 446.9998 | Validation RMSE: 413.1704 | Training R²: -0.1850 | Validation R²: -0.1116\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_mae</td><td>█▅▅▃▇▅▂▃▅▆█▄▇▅▄▆▄▆▄▅█▄▆▄▃▅▄▅▃▃▅▃▃▅▁▇▇▆▄▅</td></tr><tr><td>batch_mse</td><td>▅▅▄▄▆▅▁▆██▃▁▂▅▅▂▅▁▃▃▆▂▃▄▂▃▅▅▁▂▃█▄▁▃▃▂▃▃▅</td></tr><tr><td>batch_rmse</td><td>█▂▄▆▇▄▁▄▅▇▅▃▂▂▅▅▄▆▅▃▄▅▇▆▆▆▄▄▃▄▆▃▂▃▆▆▅▅▂▅</td></tr><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr><tr><td>epoch_avg_mae</td><td>█▅▄▄▃▃▂▂▁▁</td></tr><tr><td>epoch_avg_mse</td><td>█▅▄▄▃▃▂▂▁▁</td></tr><tr><td>epoch_avg_rmse</td><td>█▅▄▄▃▃▂▂▁▁</td></tr><tr><td>examples_seen</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇█</td></tr><tr><td>global_step</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_mae</td><td>▄▄█▂▂▅▄▅▅▄▄▄▃▄▇▅▁▃</td></tr><tr><td>train_r2</td><td>▂▅▃▆▆▃▄▆▄▁▇█▃▆▄▄▆▅</td></tr><tr><td>train_rmse</td><td>▃▄█▂▂▅▃▃▄▄▃▃▃▅▆▅▁▂</td></tr><tr><td>val_mae</td><td>█▆▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁</td></tr><tr><td>val_r2</td><td>▁▃▄▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>val_rmse</td><td>█▆▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_mae</td><td>352.6698</td></tr><tr><td>batch_mse</td><td>185355.3125</td></tr><tr><td>batch_rmse</td><td>430.52911</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>epoch_avg_mae</td><td>374.10015</td></tr><tr><td>epoch_avg_mse</td><td>218688.65504</td></tr><tr><td>epoch_avg_rmse</td><td>467.64159</td></tr><tr><td>examples_seen</td><td>5680</td></tr><tr><td>global_step</td><td>709</td></tr><tr><td>learning_rate</td><td>5e-05</td></tr><tr><td>train_mae</td><td>361.52759</td></tr><tr><td>train_r2</td><td>-0.18497</td></tr><tr><td>train_rmse</td><td>446.9998</td></tr><tr><td>val_mae</td><td>311.44541</td></tr><tr><td>val_r2</td><td>-0.11163</td></tr><tr><td>val_rmse</td><td>413.17037</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test-run-2</strong> at: <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only/runs/ejtm0bh8' target=\"_blank\">https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only/runs/ejtm0bh8</a><br> View project at: <a href='https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only' target=\"_blank\">https://wandb.ai/akshatshaw47-iit-roorkee/gpt2-corr-txt-only</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250316_230033-ejtm0bh8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 10.37 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "results = train_regressor_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=10, eval_freq=100, eval_iter=10,\n",
    "    project_name=\"gpt2-corr-txt-only\", run_name=\"test-run-2\"\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
